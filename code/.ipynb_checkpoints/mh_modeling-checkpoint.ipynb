{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_encoded = pd.read_csv('../data/agg_encode_non_self_employee.csv')\n",
    "# aggr_encoded = shuffle(aggr_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list=[\"treatment\", \"tech_company\", \"wellness_program\"]\n",
    "#14 X values no_employees, benefits,care_options, seek_help, anonymity, leave, supervisor, coworkers, family_history, phys_health_interview, mental_health_interview, obs_consequence, age, gender\n",
    "X = aggr_encoded.drop(target_list, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y1=Has the employee seek mental health treatment? (treatment)\n",
    "# y2=Is your employer primarily a tech company/organization? (tech_company)\n",
    "# y3=Will the employer bring awareness to mental health in a wellness program? (wellness_program)# Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3089, 47) (3089,)\n"
     ]
    }
   ],
   "source": [
    "y1 = aggr_encoded[\"treatment\"]\n",
    "print(X.shape, y1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, random_state=42, stratify=y1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model using the training data\n",
    "classifier.fit(X_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate the model using the test data\n",
    "treatment_log_reg_train = classifier.score(X_train, y1_train)\n",
    "treatment_log_reg_test = classifier.score(X_test, y1_test)\n",
    "print(f\"Training Data Score: {treatment_log_reg_train}\")\n",
    "print(f\"Testing Data Score: {treatment_log_reg_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 30 Predictions:   {predictions[:30]}\")\n",
    "print(f\"First 30 Actual labels: {y1_test[:30].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(classifier.predict(X_train), classifier.predict(X_train) - y1_train, c=\"blue\", label=\"Training Data\", s=100)\n",
    "plt.scatter(classifier.predict(X_test), classifier.predict(X_test) - y1_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y1_test.min(), xmax=y1_test.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at weights for each column\n",
    "pd.DataFrame({\"cols\": X.columns, \"weights\": classifier.coef_.reshape(-1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a Family history of mental illness has a strong weight to this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use decision tree model\n",
    "feature_names = X.columns\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import decision tree library\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree classifier y1 \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y1_train)  \n",
    "clf.score(X_test, y1_test)\n",
    "\n",
    "print(f\"Testing Data Score: {clf.score(X_test, y1_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Random Forest library\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest classifier y1\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y1_train)\n",
    "treatment_rf_test = rf.score(X_test, y1_test) \n",
    "print(f\"Test Data Score: {treatment_rf_train}\")\n",
    "treatment_rf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_rf_train = rf.score(X_train, y1_train)\n",
    "print(f\"Train Data Score: {treatment_rf_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age and family history are important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for y1 Treatment\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y1_train)\n",
    "    train_score = knn.score(X_train, y1_train)\n",
    "    test_score = knn.score(X_test, y1_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=19)\n",
    "knn.fit(X_train, y1_train)\n",
    "treatment_knn_train = knn.score(X_train, y1_train)\n",
    "treatment_knn_test = knn.score(X_test, y1_test)\n",
    "print('k=19 Train Acc: %.3f' % treatment_knn_train)\n",
    "print('k=19 Test Acc: %.3f' % treatment_knn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = knn.predict(X_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"no\", \"yes\"]\n",
    "\n",
    "# Create a support vector machine linear classifier and fit it to the training data\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y1_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "treatment_svm_train = model.score(X_train, y1_train)\n",
    "treatment_svm_test = model.score(X_test, y1_test)\n",
    "\n",
    "# Print the model score using the test data\n",
    "print(f\"Training Data Score: {treatment_svm_train}\")\n",
    "print(f\"Testing Data Score: {treatment_svm_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y1_test, predictions,\n",
    "                            target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target values is tech_company\n",
    "y2 = aggr_encoded[\"tech_company\"]\n",
    "print(X.shape, y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split and train\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, random_state=42, stratify=y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y2_train)\n",
    "\n",
    "tech_log_reg_train = classifier.score(X_train, y2_train)\n",
    "tech_log_reg_test = classifier.score(X_test, y2_test)\n",
    "print(f\"Training Data Score: {tech_log_reg_train}\")\n",
    "print(f\"Testing Data Score: {tech_log_reg_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has an accuracy of 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y2_test[:10].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(classifier.predict(X_train), classifier.predict(X_train) - y2_train, c=\"blue\", label=\"Training Data\", s=100)\n",
    "plt.scatter(classifier.predict(X_test), classifier.predict(X_test) - y2_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y2_test.min(), xmax=y2_test.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at weights for each column\n",
    "pd.DataFrame({\"cols\": X.columns, \"weights\": classifier.coef_.reshape(-1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of employees (1-5) has a strong weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target is tech_company\n",
    "target_names = [\"no\", \"yes\"]\n",
    "\n",
    "#Decision Tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y2_train)  \n",
    "clf.score(X_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y2_train)\n",
    "tech_rf_train = rf.score(X_train, y2_train)\n",
    "tech_rf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_rf_test = rf.score(X_test, y2_test)\n",
    "print(f\"Testing Data Score: {tech_rf_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y2_train)\n",
    "    train_score = knn.score(X_train, y2_train)\n",
    "    test_score = knn.score(X_test, y2_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train, y2_train)\n",
    "\n",
    "tech_knn_train = knn.score(X_train, y2_train)\n",
    "tech_knn_test = knn.score(X_test, y2_test)\n",
    "\n",
    "print('k=11 Test Acc: %.3f' % tech_knn_train)\n",
    "print('k=11 Train Acc: %.3f' % tech_knn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"no\", \"yes\"]\n",
    "\n",
    "# Create a support vector machine linear classifier and fit it to the training data\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y2_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "tech_svm_train = model.score(X_train, y2_train)\n",
    "tech_svm_test = model.score(X_test, y2_test)\n",
    "\n",
    "print(f\"Training Data Score: {tech_svm_train}\")\n",
    "# Print the model score using the test data\n",
    "print(f\"Testing Data Score: {tech_svm_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the classification report\n",
    "print(classification_report(y2_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wellness Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target values is wellness_program\n",
    "y3 = aggr_encoded[\"wellness_program\"]\n",
    "print(X.shape, y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train, X_test, y3_train, y3_test = train_test_split(X, y3, random_state=42, stratify=y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y3_train)\n",
    "\n",
    "wellness_log_reg_train = classifier.score(X_train, y3_train)\n",
    "wellness_log_reg_test = classifier.score(X_test, y3_test)\n",
    "\n",
    "print(f\"Training Data Score: {wellness_log_reg_train}\")\n",
    "print(f\"Testing Data Score: {wellness_log_reg_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75% Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y3_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(classifier.predict(X_train), classifier.predict(X_train) - y3_train, c=\"blue\", label=\"Training Data\", s=100)\n",
    "plt.scatter(classifier.predict(X_test), classifier.predict(X_test) - y3_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y3_test.min(), xmax=y3_test.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target is wellness_program\n",
    "target_names = [\"no\", \"yes\", \"I don't know\"]\n",
    "\n",
    "#split data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y3_train, y3_test = train_test_split(X, y3, random_state=42, stratify=y3) \n",
    "\n",
    "#Decision Tree\n",
    "# from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y3_train)  \n",
    "clf.score(X_test, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "# classifier = classifier.fit(X_train, y3_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y3_train)\n",
    "wellness_rf_train = rf.score(X_train, y3_train) \n",
    "wellness_rf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellness_rf_test = rf.score(X_test, y3_test)\n",
    "print(f\"Testing Data Score: {wellness_rf_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y3_train)\n",
    "    train_score = knn.score(X_train, y3_train)\n",
    "    test_score = knn.score(X_test, y3_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=19)\n",
    "knn.fit(X_train, y3_train)\n",
    "\n",
    "wellness_knn_train = knn.score(X_train, y3_train)\n",
    "wellness_knn_test = knn.score(X_test, y3_test)\n",
    "\n",
    "print('k=19 Test Acc: %.3f' % wellness_knn_test)\n",
    "print('k=19 Train Acc: %.3f' % wellness_knn_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"no\", \"yes\", \"I don't know\"]\n",
    "\n",
    "# Create a support vector machine linear classifier and fit it to the training data\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y3_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "wellness_svm_train = model.score(X_train, y3_train)\n",
    "wellness_svm_test = model.score(X_test, y3_test)\n",
    "\n",
    "# Print the model score using the test data\n",
    "print(f\"Testing Data Score: {wellness_svm_test}\")\n",
    "print(f\"Training Data Score: {wellness_svm_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the classification report\n",
    "print(classification_report(y3_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y1_train)\n",
    "encoded_y_train = label_encoder.transform(y1_train)\n",
    "encoded_y_test = label_encoder.transform(y1_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=47))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set early stopping as callback\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    callbacks=callbacks,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the training data\n",
    "treatment_dl_loss_train, treatment_dl_train = model.evaluate(\n",
    "    X_train_scaled, y_train_categorical, verbose=2)\n",
    "print(f\"Train Loss: {treatment_dl_loss_train}, Train Accuracy: {treatment_dl_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the testing data\n",
    "treatment_dl_loss_test, treatment_dl_test = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Test Loss: {treatment_dl_loss_test}, Test Accuracy: {treatment_dl_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "y_predict_probabilities = model.predict_proba(X_test)[:,0]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_predict_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "y_predict_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y2_train)\n",
    "encoded_y_train = label_encoder.transform(y2_train)\n",
    "encoded_y_test = label_encoder.transform(y2_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=47))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set early stopping as callback\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    callbacks=callbacks,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the training data\n",
    "tech_dl_loss_train, tech_dl_train = model.evaluate(\n",
    "    X_train_scaled, y_train_categorical, verbose=2)\n",
    "print(f\"Train Loss: {tech_dl_loss_train}, Train Accuracy: {tech_dl_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the testing data\n",
    "tech_dl_loss_test, tech_dl_test = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {tech_dl_loss_test}, Accuracy: {tech_dl_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_probabilities = model.predict_proba(X_test)[:,0]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_predict_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "y_predict_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wellness Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y3_train)\n",
    "encoded_y_train = label_encoder.transform(y3_train)\n",
    "encoded_y_test = label_encoder.transform(y3_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=47))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set early stopping as callback\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    callbacks=callbacks,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the training data\n",
    "wellness_dl_loss_train, wellness_dl_train = model.evaluate(\n",
    "    X_train_scaled, y_train_categorical, verbose=2)\n",
    "print(f\"Train Loss: {wellness_dl_loss_train}, Train Accuracy: {wellness_dl_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the testing data\n",
    "wellness_dl_loss_test, wellness_dl_test = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Test Loss: {wellness_dl_loss_test}, Test Accuracy: {wellness_dl_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.DataFrame(\n",
    "    {\"target\": [\"treatment\", \"treatment\", \"treatment\",\"treatment\",\"treatment\",\"tech_company\",\"tech_company\",\"tech_company\",\"tech_company\",\"tech_company\",\"wellness_program\",\"wellness_program\",\"wellness_program\",\"wellness_program\",\"wellness_program\"],\n",
    "     \"train_score\": [treatment_log_reg_train, treatment_rf_train, treatment_knn_train, treatment_svm_train, treatment_dl_train, tech_log_reg_train, tech_rf_train, tech_knn_train, tech_svm_train, tech_dl_train, wellness_log_reg_train, wellness_rf_train, wellness_knn_train, wellness_svm_train, wellness_dl_train],\n",
    "     \"test_score\": [treatment_log_reg_test, treatment_rf_test, treatment_knn_test, treatment_svm_test, treatment_dl_test, tech_log_reg_test, tech_rf_test, tech_knn_test, tech_svm_test, tech_dl_test, wellness_log_reg_test, wellness_rf_test, wellness_knn_test, wellness_svm_test, wellness_dl_test],\n",
    "     \"model\": [\"log_regression\", \"random_forest\", \"knn\", \"svm\", \"deep_learning\", \"log_regression\", \"random_forest\", \"knn\", \"svm\", \"deep_learning\", \"log_regression\", \"random_forest\", \"knn\", \"svm\", \"deep_learning\"]\n",
    "     })\n",
    "\n",
    "model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.to_csv(\"model_acc.csv\",\n",
    "                  encoding=\"utf-8\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
